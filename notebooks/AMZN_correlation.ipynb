{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('../scripts') # adjust the path based on actual location\n",
    "from quantitative_analysis import StockAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a630cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV\n",
    "\n",
    "apple_price_data = pd.read_csv('../src/data/yfinance_data/AMZN_historical_data.csv')\n",
    "# Create analyzer object\n",
    "\n",
    "appl_analyzer = StockAnalyzer(apple_price_data )\n",
    "# Prepare data\n",
    "appl_analyzer.prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbe2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date_column(df, col='date'):\n",
    "    \"\"\"\n",
    "    Cleans and normalizes a date column with detailed logging.\n",
    "\n",
    "    Steps:\n",
    "    - Parses to datetime\n",
    "    - Drops invalid or missing dates\n",
    "    - Normalizes to date (removes time)\n",
    "    - Removes timezone (if present)\n",
    "    - Sets column as index\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the date column\n",
    "        col (str): Name of the date column to clean\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with datetime index\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    original_rows = len(df)\n",
    "\n",
    "    # Step 1: Convert to datetime\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    after_parse_invalid = df[col].isna().sum()\n",
    "\n",
    "    # Step 2: Drop invalid dates\n",
    "    df = df.dropna(subset=[col])\n",
    "    after_drop_rows = len(df)\n",
    "\n",
    "    # Step 3: Normalize to remove time\n",
    "    df[col] = df[col].dt.normalize()\n",
    "\n",
    "    # Step 4: Remove timezone\n",
    "    if df[col].dt.tz is not None:\n",
    "        df[col] = df[col].dt.tz_localize(None)\n",
    "\n",
    "    # Step 5: Set index\n",
    "    df.set_index(col, inplace=True)\n",
    "\n",
    "    # Logging\n",
    "    print(f\"ðŸ§¼ Cleaning '{col}' column:\")\n",
    "    print(f\"   - Original rows: {original_rows}\")\n",
    "    print(f\"   - Invalid dates parsed (NaT): {after_parse_invalid}\")\n",
    "    print(f\"   - Rows remaining after cleaning: {after_drop_rows}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d41537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentiment CSV\n",
    "sentiment_df = pd.read_csv(\"../src/sentiment_with_polarity.csv\")\n",
    "\n",
    "# Filter for a specific ticker\n",
    "sentiment_df = sentiment_df[sentiment_df['stock'] == 'AMZN']\n",
    "\n",
    "print(f\"âœ… Sentiment data cleaned. Rows remaining: {len(sentiment_df)}\")\n",
    "\n",
    "# Clean the 'date' column\n",
    "sentiment_df = fix_date_column(sentiment_df, col='date')\n",
    "\n",
    "# Print number of valid rows remaining\n",
    "print(f\"âœ… Sentiment data cleaned. Rows remaining: {len(sentiment_df)}\")\n",
    "\n",
    "# Group by date to get average sentiment per day\n",
    "daily_sentiment = sentiment_df.groupby(sentiment_df.index)['polarity'].mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stock price DataFrame from your StockAnalyzer\n",
    "stock_df = appl_analyzer.df.copy()\n",
    "\n",
    "# Clean the index (if it's a 'Date' column, rename and fix that)\n",
    "stock_df.reset_index(inplace=True)\n",
    "stock_df = fix_date_column(stock_df, col='Date')\n",
    "\n",
    "# Calculate daily return\n",
    "stock_df['return'] = stock_df['Close'].pct_change() * 100\n",
    "daily_returns = stock_df[['return']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a812ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sentiment and return data on date\n",
    "merged_df = pd.merge(daily_sentiment, daily_returns, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Show number of merged rows and preview\n",
    "print(f\"ðŸ§© Merged rows: {len(merged_df)}\")\n",
    "print(\"\\nðŸ“„ Sample merged data:\")\n",
    "print(merged_df.head(10))  # change the number to see more rows\n",
    "\n",
    "# Correlation\n",
    "correlation = merged_df['polarity'].corr(merged_df['return'])\n",
    "print(f\"\\nðŸ“Š Correlation between AAPL sentiment and return: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix\n",
    "corr_matrix = merged_df.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap: Sentiment vs Return\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
